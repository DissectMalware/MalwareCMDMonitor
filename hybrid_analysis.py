import urllib.request
import json
import datetime
import os

hash_log_path = "HA - Observed Instances.hlog"

def get_HA_feed():
    url = "https://www.hybrid-analysis.com/feed?json"
    dt_now = datetime.datetime.now().strftime('%b %d %Y - %H %M %S')
    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'
    req = urllib.request.Request(
        url,
        data=None,
        headers={
            'User-Agent': user_agent
        }
    )
    response = urllib.request.urlopen(req)
    content = response.read().decode('utf-8')
    return content, dt_now


def save_feed(output_dir_path, content, retrieval_time):
    filename = 'HA - {}.rlog'.format(retrieval_time)
    with open(os.path.join(output_dir_path, filename), 'w', encoding='utf-8') as rlog:
        rlog.write(content)
    return filename

def record_file_hashes(hash_values, retrieval_time):
    with open(hash_log_path, "a", encoding="utf-8") as log_file:
        log_file.write("# {}\n".format(retrieval_time))
        for hash in hash_values:
            log_file.write(hash + "\n")

def load_file_hashes():
    hash_values = set()
    if os.path.isfile(hash_log_path):
        with open(hash_log_path, "r", encoding="utf-8") as log_file:
            for line in log_file:
                line = line.strip()
                if line.startswith("#") is False:
                    hash_values.add(line)
    return hash_values



def extract_info(content):
    # get the hashes of all instances that we has seen so far
    observed_hashes = load_file_hashes()

    obj = json.loads(content)

    commands = {}
    file_hashes = set()

    instance_template = "{}\t{}\t{}\t{}\t{}\t{}\t{}"
    for instance in obj['data']:
        sha256 = instance["sha256"]
        # check whether we has seen this instance before
        if sha256 not in observed_hashes:
            report_url = instance["reporturl"]
            thread_score = instance["threatscore"]
            analysis_time = instance["analysis_start_time"]
            file_type = instance["type"] if 'type' in instance else ""
            environment = instance["environmentDescription"]
            vt_detect = instance["vt_detect"] if 'vt_detect' in instance else ""
            instance_rec = instance_template.format("https://www.hybrid-analysis.com"+report_url, sha256, analysis_time, environment, file_type, thread_score,
                                                    vt_detect)
            file_hashes.add(sha256)
            for command in instance['process_list']:
                if 'normalizedpath' in command:
                    if 'WINDIR' in command['normalizedpath'] or 'PROGRAMFILES' in command['normalizedpath']:
                        if command['normalizedpath'] not in commands:
                            commands[command['normalizedpath']] = {}

                        if command['commandline'] not in commands[command['normalizedpath']]:
                            commands[command['normalizedpath']][command['commandline']] = set()
                        commands[command['normalizedpath']][command['commandline']].add(instance_rec)

    record_file_hashes(file_hashes, retrieval_time)

    return commands, file_hashes

def load_command_stat():
    stat = "{}"
    stat_file_path = "command_stat"
    if os.path.isfile(stat_file_path):
        with open(stat_file_path, "r", encoding="utf-8") as stat_file:
            stat = stat_file.read()
    return json.load(stat)



if __name__ == "__main__":

    content, retrieval_time = get_HA_feed()

    file_name = save_feed(".", content, retrieval_time)

    commands, observed_file_hashes = extract_info(content)

    for command, commandlines in commands.items():
        print("########################################")
        print(command)
        for commandline in commandlines:
            print("\t" + str(commandline))
            for instance in commandlines[commandline]:
                print("\t\t" + instance)




